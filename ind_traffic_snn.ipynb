{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXDvICkKXI55",
        "outputId": "c7576b9a-24eb-4adc-f994-a28f0acb4dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print 'True' if GPU is available\n",
        "print(torch.cuda.get_device_name(0))  # Prints the name of the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccWUCw9UXPEe",
        "outputId": "7be36515-9f00-4b10-97e7-57e5dbe1d269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/neelpratiksha/indian-traffic-sign-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25.8M/25.8M [00:00<00:00, 69.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/neelpratiksha/indian-traffic-sign-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"neelpratiksha/indian-traffic-sign-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdN0pkgtY5tp",
        "outputId": "655c6e76-9858-4127-ebdd-aab1560b9d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Indian-Traffic Sign-Dataset']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path where the dataset is stored\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/neelpratiksha/indian-traffic-sign-dataset/versions/1'\n",
        "\n",
        "# List the files in the dataset directory\n",
        "os.listdir(dataset_path)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Define destination path in /content/\n",
        "destination_path = '/content/indian-traffic-sign-dataset/'\n",
        "\n",
        "# Move the files from the cache to /content/\n",
        "shutil.copytree(dataset_path, destination_path)\n",
        "\n",
        "# List files in the new location\n",
        "os.listdir(destination_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZenkfsFZPU8",
        "outputId": "04b69723-2888-46d3-e4c6-dde4b106a8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \t Iteration: 0 \t Train Loss: 4.285878658294678\n",
            "Epoch: 0 \t Iteration: 100 \t Train Loss: 2.7797276973724365\n",
            "Epoch: 0 \t Iteration: 200 \t Train Loss: 1.9785447120666504\n",
            "Epoch: 1 \t Iteration: 300 \t Train Loss: 1.7038651704788208\n",
            "Epoch: 1 \t Iteration: 400 \t Train Loss: 1.913349986076355\n",
            "Epoch: 2 \t Iteration: 500 \t Train Loss: 1.4394276142120361\n",
            "Epoch: 2 \t Iteration: 600 \t Train Loss: 1.1953996419906616\n",
            "Epoch: 3 \t Iteration: 700 \t Train Loss: 0.8609333038330078\n",
            "Epoch: 3 \t Iteration: 800 \t Train Loss: 1.0258833169937134\n",
            "Epoch: 4 \t Iteration: 900 \t Train Loss: 0.751451313495636\n",
            "Epoch: 4 \t Iteration: 1000 \t Train Loss: 0.9047719240188599\n",
            "Epoch: 5 \t Iteration: 1100 \t Train Loss: 0.8374596834182739\n",
            "Epoch: 5 \t Iteration: 1200 \t Train Loss: 0.42405325174331665\n",
            "Epoch: 5 \t Iteration: 1300 \t Train Loss: 0.6453335285186768\n",
            "Epoch: 6 \t Iteration: 1400 \t Train Loss: 0.5211565494537354\n",
            "Epoch: 6 \t Iteration: 1500 \t Train Loss: 0.8875523209571838\n",
            "Epoch: 7 \t Iteration: 1600 \t Train Loss: 0.3852803707122803\n",
            "Epoch: 7 \t Iteration: 1700 \t Train Loss: 0.5484642386436462\n",
            "Epoch: 8 \t Iteration: 1800 \t Train Loss: 0.7190024852752686\n",
            "Epoch: 8 \t Iteration: 1900 \t Train Loss: 0.6250779628753662\n",
            "Epoch: 9 \t Iteration: 2000 \t Train Loss: 0.3836266100406647\n",
            "Epoch: 9 \t Iteration: 2100 \t Train Loss: 0.5234444737434387\n",
            "Test Accuracy: 88.07%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import snntorch as snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.float\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to match model input size\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Data augmentation\n",
        "    transforms.RandomRotation(10),  # Data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
        "])\n",
        "\n",
        "# Load the CSV for label mappings\n",
        "csv_file = '/content/indian-traffic-sign-dataset/Indian-Traffic Sign-Dataset/traffic_sign.csv'\n",
        "labels_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create a mapping of ClassId to label name (ClassId is the label)\n",
        "class_map = dict(zip(labels_df['ClassId'], labels_df['Name']))\n",
        "\n",
        "# Custom Dataset Class to load images and labels\n",
        "class TrafficSignDataset(Dataset):\n",
        "    def __init__(self, images_dir, csv_file, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.csv_file = csv_file\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load CSV to create a list of image paths and corresponding labels\n",
        "        self.class_map = pd.read_csv(csv_file)\n",
        "        self.class_map = dict(zip(self.class_map['ClassId'], self.class_map['Name']))\n",
        "\n",
        "        # Iterate through each class folder and collect image paths and labels\n",
        "        for class_id in os.listdir(images_dir):\n",
        "            class_folder = os.path.join(images_dir, class_id)\n",
        "            if os.path.isdir(class_folder):\n",
        "                for img_name in os.listdir(class_folder):\n",
        "                    img_path = os.path.join(class_folder, img_name)\n",
        "                    self.images.append(img_path)\n",
        "                    self.labels.append(int(class_id))  # ClassId is the label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Load the dataset\n",
        "image_dir = '/content/indian-traffic-sign-dataset/Indian-Traffic Sign-Dataset/Images'\n",
        "\n",
        "# Create dataset object\n",
        "dataset = TrafficSignDataset(images_dir=image_dir, csv_file=csv_file, transform=transform)\n",
        "\n",
        "# Split into train and test sets (80-20 split)\n",
        "train_data, test_data = train_test_split(list(zip(dataset.images, dataset.labels)), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert back to dataset format\n",
        "train_images, train_labels = zip(*train_data)\n",
        "test_images, test_labels = zip(*test_data)\n",
        "\n",
        "# Create DataLoader for train and test directly using the dataset object\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "# Network parameters\n",
        "num_inputs = 32 * 32 * 3  # Image size (32x32x3)\n",
        "num_hidden1 = 1200\n",
        "num_hidden2 = 800\n",
        "num_outputs = len(class_map)  # Number of classes (58)\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 50  # Number of time steps in the SNN\n",
        "beta = 0.9\n",
        "\n",
        "# Define the Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden1)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.fc2 = nn.Linear(num_hidden1, num_hidden2)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.fc3 = nn.Linear(num_hidden2, num_outputs)\n",
        "        self.lif3 = snn.Leaky(beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk3_rec = []\n",
        "        mem3_rec = []\n",
        "\n",
        "        # Time-loop\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x.flatten(1))  # Flatten to batch x (32*32*3)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            cur3 = self.fc3(spk2)\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            # Store results\n",
        "            spk3_rec.append(spk3)\n",
        "            mem3_rec.append(mem3)\n",
        "\n",
        "        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)  # time-steps x batch x num_outputs\n",
        "\n",
        "# Initialize network, loss function, and optimizer\n",
        "net = Net().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)  # Decreased learning rate\n",
        "\n",
        "# Training parameters\n",
        "num_epochs = 10  # Increased epochs\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    for data, targets in train_loader:\n",
        "        data, targets = data.to(device), targets.to(device)  # Move to device\n",
        "\n",
        "        # Forward pass\n",
        "        spk_rec, _ = net(data)\n",
        "\n",
        "        # Compute loss over time\n",
        "        loss_val = loss_fn(spk_rec.sum(0), targets)  # Sum spikes over time, then apply CrossEntropy\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print loss\n",
        "        if counter % 100 == 0:\n",
        "            print(f\"Epoch: {epoch} \\t Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
        "        counter += 1\n",
        "\n",
        "# Testing the model\n",
        "net.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        data, targets = data.to(device), targets.to(device)  # Move to device\n",
        "\n",
        "        # Forward pass through the network\n",
        "        spk_rec, _ = net(data)\n",
        "\n",
        "        # Sum the spikes over time and compute predictions\n",
        "        output_sum = spk_rec.sum(0)  # Sum over time\n",
        "        _, predicted = torch.max(output_sum, 1)\n",
        "\n",
        "        # Update correct predictions and total samples\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wl4A8c1a0on",
        "outputId": "4cb09d96-b3d6-4aa7-ce48-3558df309718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0  Train Loss: 5.187477111816406\n",
            "Iteration: 100  Train Loss: 2.205054759979248\n",
            "Iteration: 200  Train Loss: 1.4201500415802002\n",
            "Iteration: 300  Train Loss: 1.2325161695480347\n",
            "Iteration: 400  Train Loss: 1.19049072265625\n",
            "Iteration: 500  Train Loss: 1.3851219415664673\n",
            "Iteration: 600  Train Loss: 0.5304021835327148\n",
            "Iteration: 700  Train Loss: 0.8227061629295349\n",
            "Iteration: 800  Train Loss: 0.6850812435150146\n",
            "Iteration: 900  Train Loss: 0.5536622405052185\n",
            "Iteration: 1000  Train Loss: 0.8062125444412231\n",
            "Iteration: 1100  Train Loss: 0.45163410902023315\n",
            "Iteration: 1200  Train Loss: 0.42234915494918823\n",
            "Iteration: 1300  Train Loss: 0.44191619753837585\n",
            "Iteration: 1400  Train Loss: 0.5727237462997437\n",
            "Iteration: 1500  Train Loss: 0.5735800862312317\n",
            "Iteration: 1600  Train Loss: 0.5465282201766968\n",
            "Iteration: 1700  Train Loss: 0.5095245838165283\n",
            "Iteration: 1800  Train Loss: 0.3520330488681793\n",
            "Iteration: 1900  Train Loss: 0.5468196868896484\n",
            "Iteration: 2000  Train Loss: 0.2330668568611145\n",
            "Iteration: 2100  Train Loss: 0.47886985540390015\n",
            "ConvNetSNN Accuracy on Indian Traffic Sign Dataset: 88.88%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import snntorch as snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.float\n",
        "\n",
        "# Define transformations for the Indian Traffic Sign Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to match model input size\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Data augmentation\n",
        "    transforms.RandomRotation(10),  # Data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
        "])\n",
        "\n",
        "# Load the CSV for label mappings\n",
        "csv_file = '/content/indian-traffic-sign-dataset/Indian-Traffic Sign-Dataset/traffic_sign.csv'\n",
        "labels_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create a mapping of ClassId to label name (ClassId is the label)\n",
        "class_map = dict(zip(labels_df['ClassId'], labels_df['Name']))\n",
        "\n",
        "# Custom Dataset Class to load images and labels\n",
        "class TrafficSignDataset(Dataset):\n",
        "    def __init__(self, images_dir, csv_file, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.csv_file = csv_file\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load CSV to create a list of image paths and corresponding labels\n",
        "        self.class_map = pd.read_csv(csv_file)\n",
        "        self.class_map = dict(zip(self.class_map['ClassId'], self.class_map['Name']))\n",
        "\n",
        "        # Iterate through each class folder and collect image paths and labels\n",
        "        for class_id in os.listdir(images_dir):\n",
        "            class_folder = os.path.join(images_dir, class_id)\n",
        "            if os.path.isdir(class_folder):\n",
        "                for img_name in os.listdir(class_folder):\n",
        "                    img_path = os.path.join(class_folder, img_name)\n",
        "                    self.images.append(img_path)\n",
        "                    self.labels.append(int(class_id))  # ClassId is the label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Load the dataset\n",
        "image_dir = '/content/indian-traffic-sign-dataset/Indian-Traffic Sign-Dataset/Images'\n",
        "\n",
        "# Create dataset object\n",
        "dataset = TrafficSignDataset(images_dir=image_dir, csv_file=csv_file, transform=transform)\n",
        "\n",
        "# Split into train and test sets (80-20 split)\n",
        "train_data, test_data = train_test_split(list(zip(dataset.images, dataset.labels)), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert back to dataset format\n",
        "train_images, train_labels = zip(*train_data)\n",
        "test_images, test_labels = zip(*test_data)\n",
        "\n",
        "# Create DataLoader for train and test directly using the dataset object\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "# Network parameters\n",
        "num_inputs = 32 * 32 * 3  # Image size (32x32x3)\n",
        "num_hidden1 = 1200\n",
        "num_hidden2 = 800\n",
        "num_outputs = len(class_map)  # Number of classes\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 50  # Number of time steps in the SNN\n",
        "beta = 0.9\n",
        "\n",
        "# Define the Network (CNN + SNN)\n",
        "class ConvNetSNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional and Pooling Layers with Leaky Integrate-and-Fire (LIF) Neurons\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5, padding=\"same\")  # 3 input channels for RGB\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.mp1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 24, kernel_size=5, padding=\"same\")\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.mp2 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        self.fc = nn.Linear(24 * 8 * 8, num_outputs)  # Adjusted for 32x32 input, after pooling\n",
        "        self.lif3 = snn.Leaky(beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden states at t=0 for each LIF layer\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk3_rec = []\n",
        "        mem3_rec = []\n",
        "\n",
        "        # Time-step loop\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.conv1(x)\n",
        "            spk1, mem1 = self.lif1(self.mp1(cur1), mem1)\n",
        "            cur2 = self.conv2(spk1)\n",
        "            spk2, mem2 = self.lif2(self.mp2(cur2), mem2)\n",
        "            cur3 = self.fc(spk2.flatten(1))\n",
        "            spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "            spk3_rec.append(spk3)\n",
        "            mem3_rec.append(mem3)\n",
        "\n",
        "        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# Initialize Network\n",
        "convnet_snn = ConvNetSNN().to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(convnet_snn.parameters(), lr=1e-3)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for data, targets in train_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        convnet_snn.train()\n",
        "        spk_rec, _ = convnet_snn(data)\n",
        "\n",
        "        # Calculate loss and perform optimization\n",
        "        loss_val = loss(spk_rec.sum(0), targets)  # Sum spikes over time\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Print progress\n",
        "        if counter % 100 == 0:\n",
        "            print(f\"Iteration: {counter}  Train Loss: {loss_val.item()}\")\n",
        "        counter += 1\n",
        "\n",
        "# Accuracy Measurement Function\n",
        "def measure_accuracy(model, dataloader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for data, targets in dataloader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            spk_rec, _ = model(data)\n",
        "            spike_count = spk_rec.sum(0)\n",
        "            _, predicted = spike_count.max(1)\n",
        "\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "# Evaluate Network\n",
        "accuracy = measure_accuracy(convnet_snn, test_loader)\n",
        "print(f\"ConvNetSNN Accuracy on Indian Traffic Sign Dataset: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK1enubba4s7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}